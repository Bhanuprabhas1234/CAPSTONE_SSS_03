{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5f99ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python : 3.11.14\n",
      "Torch  : 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA device : NVIDIA GeForce GTX 1080\n",
      "Capability  : (6, 1)\n",
      "Tensor add OK on CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import torch, platform, numpy as np\n",
    "\n",
    "print(f\"Python : {platform.python_version()}\")\n",
    "print(f\"Torch  : {torch.__version__}\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device :\", torch.cuda.get_device_name(0))\n",
    "    print(\"Capability  :\", torch.cuda.get_device_capability(0))\n",
    "    # dtype-consistent CUDA op\n",
    "    a = torch.ones(2,2, device='cuda', dtype=torch.float32)\n",
    "    b = torch.ones(2,2, device='cuda', dtype=torch.float32)\n",
    "    two = torch.full((2,2), 2.0, device='cuda', dtype=torch.float32)\n",
    "    print(\"Tensor add OK on CUDA:\", torch.allclose(a+b, two))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c044db0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 PLY files for training!\n"
     ]
    }
   ],
   "source": [
    "import os, glob, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from plyfile import PlyData\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Repro\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Paths\n",
    "data_folder = \"/mnt/hdd1/desktop/SSS_03/CAPSTONE_SSS_03/Data/train_sphere_ascii_roi\"  # <-- put your ROI folder (16 PLYs)\n",
    "file_list = sorted(glob.glob(os.path.join(data_folder, \"*.ply\")))\n",
    "print(f\"Found {len(file_list)} PLY files for training!\")\n",
    "\n",
    "# Device / classes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 3\n",
    "CLASS_MAP = {\"Background\": 0, \"Track\": 1, \"Object\": 2}\n",
    "SCALAR_MAP = {1: \"Background\", 3: \"Track\", 9: \"Object\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d40855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rail3DDataset(Dataset):\n",
    "    def __init__(self, file_list, num_points=4096):\n",
    "        self.file_list = file_list\n",
    "        self.num_points = num_points\n",
    "        self.class_map = CLASS_MAP\n",
    "        self.scalar_map = SCALAR_MAP\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ply_path = self.file_list[idx]\n",
    "        ply = PlyData.read(ply_path)\n",
    "        df = pd.DataFrame(ply['vertex'].data)\n",
    "\n",
    "        # Points\n",
    "        if {'x','y','z'}.issubset(df.columns):\n",
    "            points = df[['x','y','z']].values.astype(np.float32)\n",
    "        else:\n",
    "            points = np.zeros((0,3), dtype=np.float32)\n",
    "\n",
    "        # Labels\n",
    "        col = next((c for c in [\"scalar_NewClassification\",\"scalar_Classification\",\"classification\",\"label\"]\n",
    "                    if c in df.columns), None)\n",
    "        if col is None:\n",
    "            # default BG if absent\n",
    "            raw = pd.Series([1]*len(points))\n",
    "        else:\n",
    "            raw = df[col]\n",
    "        try:\n",
    "            raw = raw.astype(int)\n",
    "        except Exception:\n",
    "            raw = pd.Series([1]*len(points))\n",
    "\n",
    "        mapped = raw.map(self.scalar_map).fillna(\"Background\")\n",
    "        labels = mapped.map(self.class_map).astype(np.int64).values\n",
    "\n",
    "        # Handle empty\n",
    "        if points.shape[0] == 0:\n",
    "            pts = np.zeros((self.num_points, 3), dtype=np.float32)\n",
    "            lbl = np.zeros((self.num_points,), dtype=np.int64)\n",
    "            return torch.from_numpy(pts), torch.from_numpy(lbl)\n",
    "\n",
    "        # Per-point inverse-frequency sampling with boosts\n",
    "        uniq, cnts = np.unique(labels, return_counts=True)\n",
    "        freq = {int(u): int(c) for u,c in zip(uniq,cnts)}\n",
    "        inv = np.array([1.0 / max(freq.get(int(l),1),1) for l in labels], dtype=np.float32)\n",
    "\n",
    "        # Emphasize Track (1) and a bit for Object (2)\n",
    "        boost = {0:1.0, 1:3.0, 2:1.5}\n",
    "        inv *= np.vectorize(boost.get)(labels.astype(int))\n",
    "\n",
    "        alpha = 0.3  # lower alpha = stronger focus on rare classes\n",
    "        inv_sum = float(inv.sum())\n",
    "        if not np.isfinite(inv_sum) or inv_sum <= 0:\n",
    "            inv = np.ones_like(inv) / len(inv)\n",
    "        p = (1 - alpha) * (inv / inv.sum()) + alpha * (1.0/len(inv))\n",
    "        p = p / p.sum()\n",
    "\n",
    "        choice = np.random.choice(len(points), self.num_points, replace=True, p=p)\n",
    "        points = points[choice]\n",
    "        labels = labels[choice]\n",
    "\n",
    "        # Normalize to unit sphere + tiny jitter\n",
    "        centroid = points.mean(axis=0, keepdims=True)\n",
    "        points = points - centroid\n",
    "        max_dist = np.sqrt((points**2).sum(axis=1)).max()\n",
    "        if max_dist > 0:\n",
    "            points = points / max_dist\n",
    "        points = points + np.random.normal(scale=0.001, size=points.shape).astype(np.float32)\n",
    "\n",
    "        return torch.from_numpy(points), torch.from_numpy(labels)\n",
    "\n",
    "dataset = Rail3DDataset(file_list, num_points=4096)\n",
    "\n",
    "# DataLoader: if workers>0 ever crash on your laptop, keep 0\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,          # try 4 on the GPU box; use 0 if you see worker crashes\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b86238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset counts: {0: 19983204, 1: 692048, 2: 4431265}\n",
      "Using smoothed class weights: [0.5        1.8971925  0.74974865]\n"
     ]
    }
   ],
   "source": [
    "def count_labels_from_files(file_list, scalar_map, class_map):\n",
    "    cnt = Counter()\n",
    "    for p in file_list:\n",
    "        ply = PlyData.read(p)\n",
    "        df = pd.DataFrame(ply['vertex'].data)\n",
    "        col = next((c for c in [\"scalar_NewClassification\",\"scalar_Classification\",\"classification\",\"label\"]\n",
    "                    if c in df.columns), None)\n",
    "        if col is None: \n",
    "            continue\n",
    "        raw = df[col].astype(int)\n",
    "        mapped = raw.map(scalar_map).map(class_map).dropna().astype(int)\n",
    "        cnt.update(mapped.tolist())\n",
    "    return cnt\n",
    "\n",
    "full_cnt = count_labels_from_files(file_list, SCALAR_MAP, CLASS_MAP)\n",
    "print(\"Full dataset counts:\", dict(full_cnt))\n",
    "\n",
    "tot = sum(full_cnt.values()) if full_cnt else 1\n",
    "raw = np.array([tot / max(full_cnt.get(c,1),1) for c in range(num_classes)], dtype=np.float32)\n",
    "w = np.sqrt(raw); w = w / w.mean(); w = np.clip(w, 0.5, 5.0)\n",
    "print(\"Using smoothed class weights:\", w)\n",
    "\n",
    "weights = torch.tensor(w, dtype=torch.float32, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db2d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STN3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):           # x: (B,3,N)\n",
    "        B = x.size(0)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=False)[0]     # (B,1024)\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        iden = torch.eye(3, device=x.device).view(1, 9).repeat(B, 1)\n",
    "        x = x + iden\n",
    "        return x.view(-1, 3, 3)\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):           # x: (B,k,N)\n",
    "        B = x.size(0)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=False)[0]     # (B,1024)\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        iden = torch.eye(self.k, device=x.device).view(1, self.k*self.k).repeat(B, 1)\n",
    "        x = x + iden\n",
    "        return x.view(-1, self.k, self.k)\n",
    "\n",
    "class PointNetSeg(nn.Module):\n",
    "    def __init__(self, num_classes=3, feature_transform=True):\n",
    "        super().__init__()\n",
    "        self.feature_transform = feature_transform\n",
    "        self.stn = STN3d()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.fstn = STNkd(k=64)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        # 64 (pointfeat) + 128 (local) + 1024 (global)\n",
    "        self.conv4 = nn.Conv1d(64+128+1024, 512, 1)\n",
    "        self.conv5 = nn.Conv1d(512, 256, 1)\n",
    "        self.conv6 = nn.Conv1d(256, 128, 1)\n",
    "        self.conv7 = nn.Conv1d(128, num_classes, 1)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.bn6 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):           # x: (B,N,3)\n",
    "        x = x.transpose(2,1).contiguous()        # (B,3,N)\n",
    "\n",
    "        trans = self.stn(x)\n",
    "        x = torch.bmm(trans, x)                  # (B,3,N)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))      # (B,64,N)\n",
    "        pointfeat = x\n",
    "\n",
    "        trans_feat = None\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = torch.bmm(trans_feat, x)         # (B,64,N)\n",
    "\n",
    "        local128 = F.relu(self.bn2(self.conv2(x)))   # (B,128,N)\n",
    "        global1024 = self.bn3(self.conv3(local128))  # (B,1024,N)\n",
    "        global_pool = torch.max(global1024, 2, keepdim=True)[0]  # (B,1024,1)\n",
    "        global_tile = global_pool.repeat(1, 1, pointfeat.size(2))# (B,1024,N)\n",
    "\n",
    "        feat = torch.cat([pointfeat, local128, global_tile], dim=1)  # (B,1216,N)\n",
    "\n",
    "        x = F.relu(self.bn4(self.conv4(feat)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.dropout(F.relu(self.bn6(self.conv6(x))))\n",
    "        x = self.conv7(x)                         # (B,C,N)\n",
    "\n",
    "        return x.transpose(2,1).contiguous(), trans, trans_feat\n",
    "\n",
    "model = PointNetSeg(num_classes=num_classes, feature_transform=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "044228d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform_regularizer(trans):\n",
    "    if trans is None:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "    B, k, _ = trans.size()\n",
    "    I = torch.eye(k, device=trans.device).unsqueeze(0).expand(B, -1, -1)\n",
    "    diff = torch.bmm(trans, trans.transpose(2,1)) - I\n",
    "    return torch.mean(torch.norm(diff, dim=(1,2)))\n",
    "\n",
    "# CE with class weights + small FT regularizer\n",
    "ce_loss = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "def seg_loss(logits, targets, trans_feat, ft_weight=1e-3):\n",
    "    ce = ce_loss(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "    reg = feature_transform_regularizer(trans_feat) * ft_weight\n",
    "    return ce + reg\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
    "\n",
    "@torch.no_grad()\n",
    "def epoch_iou_full(model, dataloader, device, num_classes=3):\n",
    "    inter = torch.zeros(num_classes, dtype=torch.long)\n",
    "    union = torch.zeros(num_classes, dtype=torch.long)\n",
    "    model.eval()\n",
    "    for P, L in dataloader:\n",
    "        P = P.to(device); L = L.to(device)\n",
    "        logits, _, _ = model(P)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        p = preds.view(-1).cpu()\n",
    "        g = L.view(-1).cpu()\n",
    "        for c in range(num_classes):\n",
    "            inter[c] += ((p==c) & (g==c)).sum()\n",
    "            union[c] += ((p==c) | (g==c)).sum()\n",
    "    return [(inter[c].item()/union[c].item()) if union[c] > 0 else float('nan')\n",
    "            for c in range(num_classes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df41cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] Loss: 1.2002 | Acc: 33.82% | IoU: [0.0, 0.015365844358866817, 0.2462753461918892]\n",
      "Epoch [2/30] Loss: 1.1778 | Acc: 34.25% | IoU: [0.0, 0.389404296875, 0.0]\n",
      "Epoch [3/30] Loss: 1.1852 | Acc: 33.23% | IoU: [0.0, 0.3923492431640625, 0.0]\n",
      "Epoch [4/30] Loss: 1.1479 | Acc: 34.81% | IoU: [0.0, 0.3924713134765625, 0.0]\n",
      "Epoch [5/30] Loss: 1.1251 | Acc: 36.01% | IoU: [0.0, 0.3929443359375, 0.0]\n",
      "Epoch [6/30] Loss: 1.0878 | Acc: 38.84% | IoU: [0.0, 0.3906707763671875, 0.0]\n",
      "Epoch [7/30] Loss: 1.0844 | Acc: 36.90% | IoU: [0.0, 0.38897705078125, 0.0]\n",
      "Epoch [8/30] Loss: 1.0551 | Acc: 37.80% | IoU: [0.0, 0.3886260986328125, 0.0]\n",
      "Epoch [9/30] Loss: 1.0732 | Acc: 36.31% | IoU: [0.0, 0.3912811279296875, 0.0]\n",
      "Epoch [10/30] Loss: 1.0409 | Acc: 38.46% | IoU: [0.0, 0.3903656005859375, 0.0]\n",
      "Epoch [11/30] Loss: 1.0302 | Acc: 36.89% | IoU: [0.0, 0.3922882080078125, 0.0]\n",
      "Epoch [12/30] Loss: 1.0014 | Acc: 39.30% | IoU: [0.0, 0.3901214599609375, 0.0]\n",
      "Epoch [13/30] Loss: 0.9864 | Acc: 39.63% | IoU: [0.0, 0.3927154541015625, 0.0]\n",
      "Epoch [14/30] Loss: 0.9740 | Acc: 38.51% | IoU: [0.0, 0.393402099609375, 0.0]\n",
      "Epoch [15/30] Loss: 0.9719 | Acc: 38.44% | IoU: [0.0, 0.38861083984375, 0.0]\n",
      "Epoch [16/30] Loss: 0.9348 | Acc: 39.76% | IoU: [0.0, 0.3907012939453125, 0.0]\n",
      "Epoch [17/30] Loss: 0.9446 | Acc: 39.42% | IoU: [0.0, 0.389617919921875, 0.0]\n",
      "Epoch [18/30] Loss: 0.9436 | Acc: 39.10% | IoU: [0.0, 0.3914947509765625, 0.0]\n",
      "Epoch [19/30] Loss: 0.9131 | Acc: 39.37% | IoU: [0.0, 0.3942718505859375, 0.0]\n",
      "Epoch [20/30] Loss: 0.9191 | Acc: 39.63% | IoU: [0.0, 0.3917388916015625, 0.0]\n",
      "Epoch [21/30] Loss: 0.9190 | Acc: 39.82% | IoU: [0.0, 0.3921356201171875, 0.0]\n",
      "Epoch [22/30] Loss: 0.9117 | Acc: 39.32% | IoU: [0.0, 0.391021728515625, 0.0]\n",
      "Epoch [23/30] Loss: 0.8804 | Acc: 39.67% | IoU: [0.0, 0.39306640625, 0.0]\n",
      "Epoch [24/30] Loss: 0.8960 | Acc: 39.08% | IoU: [0.0, 0.3920440673828125, 0.0]\n",
      "Epoch [25/30] Loss: 0.8906 | Acc: 39.65% | IoU: [0.0, 0.3909149169921875, 0.0]\n",
      "Epoch [26/30] Loss: 0.8704 | Acc: 39.47% | IoU: [0.0, 0.39447021484375, 0.0]\n",
      "Epoch [27/30] Loss: 0.8612 | Acc: 39.49% | IoU: [0.0, 0.39202880859375, 0.0]\n",
      "Epoch [28/30] Loss: 0.8569 | Acc: 39.67% | IoU: [0.0, 0.3923797607421875, 0.0]\n",
      "Epoch [29/30] Loss: 0.8506 | Acc: 39.64% | IoU: [0.0, 0.3935292380848782, 0.06715912588488766]\n",
      "Epoch [30/30] Loss: 0.8891 | Acc: 40.43% | IoU: [0.0, 0.39427786678873883, 0.0]\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "save_dir = \"./checkpoints_pointnet\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    run_loss, total_pts, correct = 0.0, 0, 0\n",
    "\n",
    "    for P, L in dataloader:\n",
    "        P = P.to(device, non_blocking=True)  # (B,N,3)\n",
    "        L = L.to(device, non_blocking=True)  # (B,N)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            logits, trans, trans_feat = model(P)          # logits: (B,N,C)\n",
    "            loss = seg_loss(logits, L, trans_feat, ft_weight=1e-3)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        run_loss += loss.item() * P.size(0)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        correct += (preds == L).sum().item()\n",
    "        total_pts += L.numel()\n",
    "\n",
    "    avg_loss = run_loss / len(dataset)\n",
    "    acc = 100.0 * correct / total_pts\n",
    "\n",
    "    # full-epoch IoU (uses model.eval() internally)\n",
    "    ious = epoch_iou_full(model, dataloader, device, num_classes=num_classes)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{epochs}] Loss: {avg_loss:.4f} | Acc: {acc:.2f}% | IoU: {ious}\")\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"best_pointnet.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8aa97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
