{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b727d5ec",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a1c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports, paths, seeds, device ---\n",
    "import os, glob, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from plyfile import PlyData\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53d9c0d",
   "metadata": {},
   "source": [
    "# Loading Dataset path and checking if gpu is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81886605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_FOLDER = r\"C:\\Users\\bhanu\\OneDrive\\Desktop\\capstone\\Data\\train_sphere_ascii_roi\"  # ROI folder\n",
    "\n",
    "# Repro\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cde31e",
   "metadata": {},
   "source": [
    "# Just cross verying the number of files in the folder , Just a basic check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6efe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: 12\n",
      "\n",
      "First few files:\n",
      " Sphere_10_ascii_roi.ply\n",
      "Sphere_11_ascii_roi.ply\n",
      "Sphere_12_ascii_roi.ply\n",
      "Sphere_15_ascii_roi.ply\n",
      "Sphere_1_ascii_roi.ply\n"
     ]
    }
   ],
   "source": [
    "# --- List ROI .ply files ---\n",
    "file_list = sorted(glob.glob(os.path.join(DATA_FOLDER, \"*.ply\")))\n",
    "print(\"Found files:\", len(file_list))\n",
    "assert len(file_list) > 0, \"No PLY files found in ROI folder.\"\n",
    "print(\"\\nFirst few files:\\n\", \"\\n\".join(os.path.basename(f) for f in file_list[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a75dad",
   "metadata": {},
   "source": [
    "# Label mapping + verify mapping on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69fadef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad files: 0\n",
      "Counts [id: count]: {0: 12717193, 1: 541178, 2: 4012529}\n",
      "Ratios: {0: 0.7363, 1: 0.0313, 2: 0.2323}\n",
      "\n",
      "✅ Mapping verified: 0=Background, 1=Track, 2=Object\n"
     ]
    }
   ],
   "source": [
    "# --- Mapping: raw ASCII -> name -> id (final) ---\n",
    "SCALAR_MAP = {1: \"Background\", 3: \"Track\", 9: \"Object\"}\n",
    "CLASS_MAP  = {\"Background\": 0, \"Track\": 1, \"Object\": 2}\n",
    "LABEL_CANDIDATES = [\"scalar_NewClassification\", \"scalar_Classification\", \"classification\", \"label\"]\n",
    "\n",
    "def find_label_column(df):\n",
    "    for c in LABEL_CANDIDATES:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# Scan all files, count mapped classes, and verify only 0/1/2 appear\n",
    "cnt = Counter()\n",
    "bad_files = []\n",
    "for f in file_list:\n",
    "    try:\n",
    "        df = pd.DataFrame(PlyData.read(f)[\"vertex\"].data)\n",
    "        col = find_label_column(df)\n",
    "        if col is None:\n",
    "            raise ValueError(\"No label column\")\n",
    "        raw = df[col].astype(int)\n",
    "\n",
    "        mapped_name = raw.map(SCALAR_MAP).fillna(\"Background\")\n",
    "        mapped_id = mapped_name.map(CLASS_MAP).astype(int)\n",
    "\n",
    "        uniq = set(mapped_id.unique().tolist())\n",
    "        if not uniq.issubset({0,1,2}):\n",
    "            raise ValueError(f\"Unexpected mapped ids: {uniq}\")\n",
    "\n",
    "        cnt.update(mapped_id.tolist())\n",
    "    except Exception as e:\n",
    "        print(f\"[BAD] {os.path.basename(f)} -> {e}\")\n",
    "        bad_files.append(f)\n",
    "\n",
    "print(\"\\nBad files:\", len(bad_files))\n",
    "print(\"Counts [id: count]:\", dict(cnt))\n",
    "total = sum(cnt.values())\n",
    "if total > 0:\n",
    "    ratios = {k: round(v/total, 4) for k,v in cnt.items()}\n",
    "    print(\"Ratios:\", ratios)\n",
    "\n",
    "# Final assertion\n",
    "assert len(bad_files) == 0, \"Some files failed label checks. Fix or remove before training.\"\n",
    "print(\"\\n✅ Mapping verified: 0=Background, 1=Track, 2=Object\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ca62f",
   "metadata": {},
   "source": [
    "# Dataset (light, with mild class-balancing sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48a6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Light Dataset: normalize -> mild balanced sampling -> jitter ---\n",
    "\n",
    "class Rail3DDataset(Dataset):\n",
    "    def __init__(self, file_list, num_points=4096, sampling=True):\n",
    "        self.file_list = file_list\n",
    "        self.num_points = num_points\n",
    "        self.sampling = sampling\n",
    "        self.scalar_map = SCALAR_MAP\n",
    "        self.class_map = CLASS_MAP\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ply_path = self.file_list[idx]\n",
    "        df = pd.DataFrame(PlyData.read(ply_path)[\"vertex\"].data)\n",
    "\n",
    "        # points\n",
    "        if {\"x\",\"y\",\"z\"}.issubset(df.columns):\n",
    "            pts = df[[\"x\",\"y\",\"z\"]].to_numpy(dtype=np.float32)\n",
    "        else:\n",
    "            pts = np.zeros((0,3), np.float32)\n",
    "\n",
    "        # labels\n",
    "        col = find_label_column(df)\n",
    "        if col is None:\n",
    "            raw = pd.Series([1]*len(pts))  # fallback to Background raw=1\n",
    "        else:\n",
    "            raw = df[col].astype(int)\n",
    "\n",
    "        mapped_name = raw.map(self.scalar_map).fillna(\"Background\")\n",
    "        lbl = mapped_name.map(self.class_map).astype(np.int64).to_numpy()\n",
    "\n",
    "        # handle empty\n",
    "        if pts.shape[0] == 0:\n",
    "            pts = np.zeros((self.num_points,3), np.float32)\n",
    "            lbl = np.zeros((self.num_points,), np.int64)\n",
    "\n",
    "        # sampling (mild class balance, avoids collapse)\n",
    "        if self.sampling and len(pts) > 0:\n",
    "            # per-class frequency\n",
    "            uniq, counts = np.unique(lbl, return_counts=True)\n",
    "            freq = {int(u): int(c) for u,c in zip(uniq, counts)}\n",
    "            inv = np.array([1.0 / max(freq.get(int(l),1), 1) for l in lbl], dtype=np.float32)\n",
    "\n",
    "            # mild boost: favor Object, slightly Track\n",
    "            boost = {0: 1.0, 1: 1.4, 2: 1.8}\n",
    "            inv *= np.vectorize(boost.get)(lbl.astype(int))\n",
    "\n",
    "            # blend with uniform for stability\n",
    "            alpha = 0.6  # more uniform than rare; safer\n",
    "            uniform = np.full_like(inv, 1.0/len(inv), np.float32)\n",
    "            p = (1 - alpha) * (inv / max(inv.sum(), 1e-12)) + alpha * uniform\n",
    "            p = p / p.sum()\n",
    "\n",
    "            choice = np.random.choice(len(pts), self.num_points, replace=True, p=p)\n",
    "            pts = pts[choice]\n",
    "            lbl = lbl[choice]\n",
    "        else:\n",
    "            # uniform sample/pad\n",
    "            if len(pts) >= self.num_points:\n",
    "                choice = np.random.choice(len(pts), self.num_points, replace=False)\n",
    "            else:\n",
    "                choice = np.random.choice(len(pts), self.num_points, replace=True)\n",
    "            pts = pts[choice]\n",
    "            lbl = lbl[choice]\n",
    "\n",
    "        # normalize to unit sphere + tiny jitter\n",
    "        centroid = pts.mean(axis=0, keepdims=True)\n",
    "        pts = pts - centroid\n",
    "        max_dist = np.sqrt((pts**2).sum(axis=1)).max()\n",
    "        if max_dist > 0:\n",
    "            pts = pts / max_dist\n",
    "        pts = pts + np.random.normal(scale=0.001, size=pts.shape).astype(np.float32)\n",
    "\n",
    "        return torch.from_numpy(pts).float(), torch.from_numpy(lbl).long()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7af1d",
   "metadata": {},
   "source": [
    "# Dataloader + batch sanity print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64ba373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9686, 1: 2571, 2: 4127}\n",
      "{0: 8400, 1: 2496, 2: 5488}\n",
      "{0: 8451, 1: 2431, 2: 5502}\n"
     ]
    }
   ],
   "source": [
    "# --- Dataloader (start with workers=0 for laptop stability) ---\n",
    "dataset = Rail3DDataset(file_list, num_points=4096, sampling=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,        # set >0 later if stable\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "# quick sanity on batch label distribution (3 batches)\n",
    "for i, (_, L) in enumerate(dataloader):\n",
    "    vals, cnts = torch.unique(L, return_counts=True)\n",
    "    print({int(v): int(c) for v,c in zip(vals, cnts)})\n",
    "    if i == 2: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3980d667",
   "metadata": {},
   "source": [
    "# Light model (PointMLP-lite with BN/Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35726255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointMLPLite on cuda\n"
     ]
    }
   ],
   "source": [
    "# --- Light per-point model (MLP + BatchNorm + Dropout) ---\n",
    "class PointMLPLite(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(3, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.head = nn.Linear(256, num_classes)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "\n",
    "        # init\n",
    "        for m in [self.fc1,self.fc2,self.fc3,self.head]:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,N,3)\n",
    "        B, N, _ = x.shape\n",
    "        x = x.view(B*N, -1)\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.do(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.do(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.head(x)\n",
    "        x = x.view(B, N, -1)\n",
    "        return x\n",
    "\n",
    "model = PointMLPLite(num_classes=3, dropout=0.2).to(device)\n",
    "print(model.__class__.__name__, \"on\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5f667",
   "metadata": {},
   "source": [
    "# Class weights from counts + loss/opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f36f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights [BG,Track,Obj]: [0.5       1.9065322 0.7001726]\n"
     ]
    }
   ],
   "source": [
    "# --- Class weights from dataset counts (sqrt-smooth, mean-norm, clipped) ---\n",
    "arr = np.array([cnt.get(0,0), cnt.get(1,0), cnt.get(2,0)], dtype=np.float32)  # [BG, Track, Obj]\n",
    "total = arr.sum()\n",
    "raw = total / np.maximum(arr, 1.0)\n",
    "w = np.sqrt(raw)\n",
    "w = w / w.mean()\n",
    "w = np.clip(w, 0.5, 2.0)  # gentle\n",
    "weights = torch.tensor(w, dtype=torch.float32, device=device)\n",
    "print(\"Class weights [BG,Track,Obj]:\", w)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# AMP scaler\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d519898",
   "metadata": {},
   "source": [
    "# Metrics (IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3efb70f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IoU per class ---\n",
    "def iou_per_class(preds, labels, num_classes=3):\n",
    "    preds = preds.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    ious = []\n",
    "    for c in range(num_classes):\n",
    "        inter = ((preds == c) & (labels == c)).sum().item()\n",
    "        union = ((preds == c) | (labels == c)).sum().item()\n",
    "        ious.append(float('nan') if union == 0 else inter / union)\n",
    "    return ious\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed59257a",
   "metadata": {},
   "source": [
    "# Traning loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff467ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Loss: 1.3610 | Acc: 24.69% | IoU: [0.0348721355031551, 0.15284087373203062, 0.0]\n",
      "Epoch [2/15] Loss: 1.3447 | Acc: 24.51% | IoU: [0.0931098696461825, 0.15101315321720582, 0.0]\n",
      "Epoch [3/15] Loss: 1.3385 | Acc: 24.92% | IoU: [0.22530737704918033, 0.12866610265087422, 0.0]\n",
      "Epoch [4/15] Loss: 1.3079 | Acc: 25.01% | IoU: [0.14259866561121792, 0.1370994603957098, 0.0]\n",
      "Epoch [5/15] Loss: 1.2718 | Acc: 25.10% | IoU: [0.005770136599152143, 0.15697275730939467, 0.0]\n",
      "Epoch [6/15] Loss: 1.2574 | Acc: 24.56% | IoU: [0.049921073401736384, 0.1713860965595356, 0.0]\n",
      "Epoch [7/15] Loss: 1.2364 | Acc: 26.46% | IoU: [0.15792838874680307, 0.13831001998287182, 0.001682935038707506]\n",
      "Epoch [8/15] Loss: 1.2317 | Acc: 26.88% | IoU: [0.1407177168691721, 0.14568810213832536, 0.0]\n",
      "Epoch [9/15] Loss: 1.2234 | Acc: 26.67% | IoU: [0.15479384003974167, 0.16302039082412914, 0.30575124887921096]\n",
      "Epoch [10/15] Loss: 1.2196 | Acc: 27.39% | IoU: [0.13505612722170252, 0.1393766809049201, 0.21314461883408073]\n",
      "Epoch [11/15] Loss: 1.1815 | Acc: 28.81% | IoU: [0.11076074103271581, 0.15603341034298915, 0.1925238898257448]\n",
      "Epoch [12/15] Loss: 1.1703 | Acc: 29.04% | IoU: [0.12133477244108652, 0.16636037455150082, 0.22958913771821549]\n",
      "Epoch [13/15] Loss: 1.1806 | Acc: 30.38% | IoU: [0.18315277918396275, 0.14866310160427806, 0.2787141073657928]\n",
      "Epoch [14/15] Loss: 1.1636 | Acc: 30.83% | IoU: [0.2504856354156017, 0.15209861450692747, 0.40094124791255503]\n",
      "Epoch [15/15] Loss: 1.1578 | Acc: 31.95% | IoU: [0.21838968145397694, 0.1346089291708627, 0.2517249876786594]\n"
     ]
    }
   ],
   "source": [
    "# --- Train loop ---\n",
    "epochs = 15\n",
    "best_loss = float('inf')\n",
    "save_dir = \"./checkpoints_light\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total_pts = 0\n",
    "\n",
    "    for P, L in dataloader:\n",
    "        P = P.to(device, non_blocking=True)\n",
    "        L = L.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            logits = model(P)                          # (B,N,C)\n",
    "            loss = criterion(logits.view(-1,3), L.view(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * P.size(0)\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        correct += (preds == L).sum().item()\n",
    "        total_pts += L.numel()\n",
    "\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    acc = 100.0 * correct / total_pts\n",
    "\n",
    "    # quick IoU on a few batches (cheap)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        P_s, L_s = next(iter(dataloader))\n",
    "        P_s = P_s.to(device); L_s = L_s.to(device)\n",
    "        preds_s = model(P_s).argmax(dim=-1)\n",
    "        ious = iou_per_class(preds_s.cpu(), L_s.cpu(), num_classes=3)\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{epochs}] Loss: {avg_loss:.4f} | Acc: {acc:.2f}% | IoU: {ious}\")\n",
    "\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # save best\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"best_light.pth\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da69b3",
   "metadata": {},
   "source": [
    "# POINTNET-SEGMENTATION ACTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dfb91c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PointNet building blocks ----\n",
    "class STN3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,3,N)\n",
    "        B = x.size(0)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))           # (B,1024,N)\n",
    "        x = torch.max(x, 2, keepdim=False)[0]         # (B,1024)\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        iden = torch.eye(3, device=x.device).view(1, 9).repeat(B, 1)\n",
    "        x = x + iden\n",
    "        return x.view(-1, 3, 3)\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k*k)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,k,N)\n",
    "        B = x.size(0)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=False)[0]         # (B,1024)\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        iden = torch.eye(self.k, device=x.device).view(1, self.k*self.k).repeat(B, 1)\n",
    "        x = x + iden\n",
    "        return x.view(-1, self.k, self.k)\n",
    "\n",
    "# ---- PointNetSeg (per-point + global features) ----\n",
    "class PointNetSeg(nn.Module):\n",
    "    def __init__(self, num_classes=3, feature_transform=True):\n",
    "        super().__init__()\n",
    "        self.feature_transform = feature_transform\n",
    "\n",
    "        self.stn = STN3d()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.fstn = STNkd(k=64)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        # Segmentation head: concat per-point (64,128) with global (1024)\n",
    "        self.conv4 = nn.Conv1d(64 + 128 + 1024, 512, 1)\n",
    "        self.conv5 = nn.Conv1d(512, 256, 1)\n",
    "        self.conv6 = nn.Conv1d(256, 128, 1)\n",
    "        self.conv7 = nn.Conv1d(128, num_classes, 1)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.bn6 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,N,3) -> to (B,3,N)\n",
    "        x = x.transpose(2, 1).contiguous()\n",
    "\n",
    "        # input transform\n",
    "        trans = self.stn(x)\n",
    "        x = torch.bmm(trans, x)                   # (B,3,N)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))       # (B,64,N)\n",
    "        pointfeat = x                             # save 64-d per-point\n",
    "\n",
    "        # feature transform\n",
    "        trans_feat = None\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = torch.bmm(trans_feat, x)         # still (B,64,N)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))       # (B,128,N)\n",
    "        x = self.bn3(self.conv3(x))               # (B,1024,N)\n",
    "        x = torch.max(x, 2, keepdim=True)[0]      # (B,1024,1)\n",
    "        x = x.repeat(1, 1, pointfeat.size(2))     # (B,1024,N)\n",
    "\n",
    "        x = torch.cat([pointfeat,                # 64\n",
    "                       F.relu(self.bn2(self.conv2(pointfeat))),  # 128 on pointfeat\n",
    "                       x], dim=1)                # 1024\n",
    "        # Now (B,64+128+1024, N)\n",
    "\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.dropout(F.relu(self.bn6(self.conv6(x))))\n",
    "        x = self.conv7(x)                         # (B,C,N)\n",
    "\n",
    "        return x.transpose(2, 1).contiguous(), trans, trans_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd53ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform_regularizer(trans):\n",
    "    # trans: (B,k,k)\n",
    "    if trans is None:\n",
    "        return 0.0\n",
    "    B, k, _ = trans.size()\n",
    "    I = torch.eye(k, device=trans.device).unsqueeze(0).expand(B, -1, -1)\n",
    "    diff = torch.bmm(trans, trans.transpose(2, 1)) - I\n",
    "    return torch.mean(torch.norm(diff, dim=(1, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b62ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device, model\n",
    "model = PointNetSeg(num_classes=3, feature_transform=True).to(device)\n",
    "\n",
    "# Keep your class weights from ROI (tensor 'weights' you already compute)\n",
    "ce_loss = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# Combine CE + small feature-transform regularizer\n",
    "def seg_loss(logits, targets, trans_feat, ft_weight=0.001):\n",
    "    ce = ce_loss(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "    reg = feature_transform_regularizer(trans_feat) * ft_weight\n",
    "    return ce + reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b0da91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b04c92c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Loss: 1.2686 | Acc: 37.58% | IoU: [0.35132809362629797, 0.12551703391742497, 0.1571156462585034]\n",
      "Epoch [2/15] Loss: 1.2740 | Acc: 34.34% | IoU: [0.33905415713196035, 0.1363428772176357, 0.03396505045532858]\n",
      "Epoch [3/15] Loss: 1.2858 | Acc: 35.68% | IoU: [0.3384538232111278, 0.13194417746338089, 0.0760611809343135]\n",
      "Epoch [4/15] Loss: 1.2665 | Acc: 35.02% | IoU: [0.34945228193209926, 0.13667127574412344, 0.035669698591046906]\n",
      "Epoch [5/15] Loss: 1.2578 | Acc: 35.02% | IoU: [0.3470052083333333, 0.12819582955575703, 0.053080341059205]\n",
      "Epoch [6/15] Loss: 1.2386 | Acc: 33.47% | IoU: [0.3174984310622391, 0.12834205303987012, 0.07199222323879231]\n",
      "Epoch [7/15] Loss: 1.2195 | Acc: 35.24% | IoU: [0.33366314242098716, 0.12820236813778257, 0.10977053616733382]\n",
      "Epoch [8/15] Loss: 1.2045 | Acc: 34.35% | IoU: [0.281580077286389, 0.14194663497893487, 0.16598086891465827]\n",
      "Epoch [9/15] Loss: 1.2105 | Acc: 34.68% | IoU: [0.27671387429114336, 0.1264714875401315, 0.20616390380574365]\n",
      "Epoch [10/15] Loss: 1.1857 | Acc: 38.20% | IoU: [0.28992621593133566, 0.13979011455579587, 0.26491244498548555]\n",
      "Epoch [11/15] Loss: 1.2389 | Acc: 33.32% | IoU: [0.2958043803324831, 0.12504253790600067, 0.1395816761031304]\n",
      "Epoch [12/15] Loss: 1.1859 | Acc: 36.87% | IoU: [0.30491480409417804, 0.13629286446663882, 0.21210482324598062]\n",
      "Epoch [13/15] Loss: 1.2045 | Acc: 38.73% | IoU: [0.29222666705039285, 0.13760810144732716, 0.26188009549119406]\n",
      "Epoch [14/15] Loss: 1.1683 | Acc: 38.70% | IoU: [0.30391004190407284, 0.13730430831508944, 0.25640323243391316]\n",
      "Epoch [15/15] Loss: 1.1642 | Acc: 42.65% | IoU: [0.33348988757448556, 0.1323633950997583, 0.3072031031527671]\n"
     ]
    }
   ],
   "source": [
    "# ---- loss setup (keep your 'weights' from ROI) ----\n",
    "ce_loss = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "def feature_transform_regularizer(trans):\n",
    "    if trans is None:\n",
    "        return torch.tensor(0.0, device=weights.device)\n",
    "    B, k, _ = trans.size()\n",
    "    I = torch.eye(k, device=trans.device).unsqueeze(0).expand(B, -1, -1)\n",
    "    diff = torch.bmm(trans, trans.transpose(2, 1)) - I\n",
    "    return torch.mean(torch.norm(diff, dim=(1, 2)))\n",
    "\n",
    "def seg_loss(logits, targets, trans_feat, ft_weight=1e-3):\n",
    "    ce = ce_loss(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "    reg = feature_transform_regularizer(trans_feat) * ft_weight\n",
    "    return ce + reg\n",
    "\n",
    "# ---- optimizer / scheduler (OK to keep your previous ones) ----\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)  # a touch higher works well for PointNet\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
    "\n",
    "# --- Train loop (PointNetSeg) ---\n",
    "epochs = 15\n",
    "best_loss = float('inf')\n",
    "save_dir = \"./checkpoints_pointnet\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_pts = 0\n",
    "    correct = 0\n",
    "\n",
    "    # epoch IoU accumulators (CPU tensors)\n",
    "    inter = torch.zeros(num_classes, dtype=torch.long)\n",
    "    union = torch.zeros(num_classes, dtype=torch.long)\n",
    "\n",
    "    for P, L in dataloader:\n",
    "        P = P.to(device, non_blocking=True)   # (B,N,3)\n",
    "        L = L.to(device, non_blocking=True)   # (B,N)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
    "            # PointNetSeg returns: (logits, trans, trans_feat)\n",
    "            logits, trans, trans_feat = model(P)     # logits: (B,N,C)\n",
    "            loss = seg_loss(logits, L, trans_feat, ft_weight=1e-3)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # metrics\n",
    "        running_loss += loss.item() * P.size(0)\n",
    "        preds = logits.argmax(dim=-1)  # (B,N)\n",
    "        correct += (preds == L).sum().item()\n",
    "        total_pts += L.numel()\n",
    "\n",
    "        # IoU accumulators on CPU\n",
    "        p = preds.detach().cpu().view(-1)\n",
    "        g = L.detach().cpu().view(-1)\n",
    "        for c in range(num_classes):\n",
    "            inter[c] += ((p == c) & (g == c)).sum()\n",
    "            union[c] += ((p == c) | (g == c)).sum()\n",
    "\n",
    "    avg_loss = running_loss / len(dataset)\n",
    "    acc = 100.0 * correct / total_pts\n",
    "    ious = [(inter[c].item() / union[c].item()) if union[c] > 0 else float('nan')\n",
    "            for c in range(num_classes)]\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{epochs}] Loss: {avg_loss:.4f} | Acc: {acc:.2f}% | IoU: {ious}\")\n",
    "\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"best_pointnet.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eeb121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
